{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92Z3QOwpFTzA"
      },
      "source": [
        "# Facial Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRwf-XccnSRI"
      },
      "outputs": [],
      "source": [
        "%pip install torch\n",
        "%pip install facenet_pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "GzBS_yPem-Ll"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from PIL import Image\n",
        "from facenet_pytorch import MTCNN, InceptionResnetV1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wj6DNTIFXqU"
      },
      "source": [
        "## Reading input data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdlcHTlZqiRO",
        "outputId": "7a0e6984-6f1e-4270-e873-a3c8e0195f98"
      },
      "outputs": [],
      "source": [
        "# Using FaceNet to obtain embeddings (vector) of faces\n",
        "# Reading npy files\n",
        "embeddings = np.load('../data/embeddings.npy')\n",
        "labels = np.load('../data/labels.npy')\n",
        "\n",
        "# Getting LabelEncoder\n",
        "with open('../data/label_encoder.pkl', 'rb') as f:\n",
        "  label_encoder = pickle.load(f)\n",
        "\n",
        "# Debug\n",
        "print(embeddings.shape)\n",
        "print(labels.shape)\n",
        "print(label_encoder.inverse_transform(labels)[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3XcyngcqKiM"
      },
      "source": [
        "## Training and evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "Ll3cxx9-lERt",
        "outputId": "d2dc091d-5dd5-437f-dcc4-554c3ddf2ff6"
      },
      "outputs": [],
      "source": [
        "# Splitting data into training and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(embeddings, labels, test_size=0.05, random_state=2)\n",
        "\n",
        "# Training the metric learning model using KNN\n",
        "# -- I will substitute KNN -- \n",
        "knn = KNeighborsClassifier(n_neighbors=1)\n",
        "knn.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRjB6IkrovsL",
        "outputId": "f3ffcbf3-bfa3-4fc3-9642-1ecfc8e086ab"
      },
      "outputs": [],
      "source": [
        "# Evaluating the model\n",
        "accuracy = knn.score(x_test, y_test)\n",
        "print(\"Score:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pie5U7jlq2wp"
      },
      "source": [
        "## Including new person"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "SWf6bQfGrv2O"
      },
      "outputs": [],
      "source": [
        "# Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# MTCNN model for facial recognition\n",
        "mtcnn = MTCNN(image_size=112, margin=0, min_face_size=20, thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True, device=device)\n",
        "\n",
        "# FaceNet model (InceptionResnetV1)\n",
        "model = InceptionResnetV1(pretrained='vggface2').eval().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to extract facial embeddings using FaceNet\n",
        "def extract_face_embeddings(img_path):\n",
        "  img = Image.open(img_path).convert('RGB')\n",
        "  img = img.resize((112, 112))\n",
        "  img_cropped = mtcnn(img)\n",
        "  if img_cropped is not None:\n",
        "    with torch.no_grad():\n",
        "      embedding = model(img_cropped.unsqueeze(0).to(device))\n",
        "    return embedding.squeeze().cpu().numpy()\n",
        "  return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Sc3DScmINtHT",
        "outputId": "5fd00ef0-2d02-4450-fd1e-5dcd04c29713"
      },
      "outputs": [],
      "source": [
        "# Including new person\n",
        "emb = extract_face_embeddings('../data/newperson.jpg')\n",
        "display(Image.open('../data/newperson.jpg'))\n",
        "emb = emb.reshape(1, -1)\n",
        "embeddings = np.vstack([embeddings, emb])\n",
        "# Decoding the labels\n",
        "labels = label_encoder.inverse_transform(labels)\n",
        "labels = np.append(labels, 'New Person')\n",
        "print(labels.shape)\n",
        "print(f'{labels[-1]} was added!')\n",
        "labels = label_encoder.fit_transform(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to recognize the person given a new image\n",
        "def recognize_person(img_path):\n",
        "  img = Image.open(img_path).convert('RGB')\n",
        "  img = img.resize((112, 112))\n",
        "  img_cropped = mtcnn(img)\n",
        "  if img_cropped is not None:\n",
        "    with torch.no_grad():\n",
        "      embedding = model(img_cropped.unsqueeze(0).to(device)).squeeze().cpu().numpy()\n",
        "    predicted_label = knn.predict([embedding])[0]\n",
        "    predicted_person = label_encoder.inverse_transform([predicted_label])[0]\n",
        "    return predicted_person\n",
        "  return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "seqaJSljUWTm",
        "outputId": "4ebb0b98-d9b7-4f5c-8434-2ea7409db614"
      },
      "outputs": [],
      "source": [
        "# Testing inference on a new image\n",
        "new_image_path = '../data/newpersontest.jpg'\n",
        "display(Image.open(new_image_path))\n",
        "predicted_person = recognize_person(new_image_path)\n",
        "print(\"Predicted person:\", predicted_person)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
